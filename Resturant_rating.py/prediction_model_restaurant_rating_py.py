# -*- coding: utf-8 -*-
"""Prediction_model_Restaurant_rating.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KfVP1KV3IGjOMSdbcpqnqe0fKprw_Tc2
"""

#Build a machine learning model to predict the
#aggregate rating of a restaurant based on other features.

#libraries needed
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

file=('/content/drive/MyDrive/data_cognifyz/Dataset .csv')

df = pd.read_csv('/content/drive/MyDrive/data_cognifyz/Dataset .csv')

#data vizualization:
df.head()

df.shape

"""1)handling missing values"""

#checking for missing values :
df.isnull().sum()

#here we have very less no of missing values compared to the size of dataset,therefore directly ignoring the null values
#will not affect the distribution of ratings much,
df= df.dropna()

#checking if missing values removed or not:
df.isnull().sum().sum()

"""2)preprocessing dataset to customize it into info as per our relevance"""

#finding the dtypes
df.dtypes

#dropping columns that are subjective or non-categorial and don't contribute to aggregate rating and are hindrance to encoding: irelevant
#to shorten dataset for ease of implementation and for faster processing
columns_to_drop = ['Restaurant ID','Restaurant Name','Country Code','City','Address','Locality','Locality Verbose','Longitude','Latitude','Cuisines','Currency']

df1 = df.drop(columns=columns_to_drop, axis=1 , inplace=True )

df_1 = pd.DataFrame(df)

df_1.head()

df_1.dtypes

"""# 3)Encoding categorial variables in processed dataset for downstream tasks"""

from sklearn.preprocessing import LabelEncoder
categorial_cols=['Has Table booking','Has Online delivery','Is delivering now','Switch to order menu','Rating color','Rating text']

label_encoder = {}
for col in categorial_cols:
  label_encoder[col] = LabelEncoder()
  df_1[col]=label_encoder[col].fit_transform(df_1[col])

df_1.head()

# @title Aggregate rating vs votes
from matplotlib import pyplot as plt
df_1.plot(kind='scatter', x='Aggregate rating', y='Votes', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

#checking the correlation (strength and direction of relationship ) b/w selected indp variables
import seaborn as sns
corr_matrix = df_1.corr()
plt.figure(figsize = (10,12))
sns.heatmap(corr_matrix,annot=True,cmap='coolwarm',fmt=".2f")
plt.title('correlation b/w the selected features')
plt.show()

from sklearn.model_selection import train_test_split
X = df_1.drop(['Aggregate rating'],axis=1)
y = df_1['Aggregate rating']

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=200)

y_train.head()

df_1.info()

print("traning set size : ",len(X_train))
print("length of tsting set : ",len(X_test))

"""# -> Selecting and training **Regression** Model

# 1)Linear Regression model (LR)
"""

#selecting model
from sklearn.linear_model import LinearRegression
linear_model = LinearRegression()
linear_model.fit(X_train,y_train)

"""# **Testing Model**"""

y_pred = linear_model.predict(X_test)

"""# **EVALUATING MODEL'S PERFORMANCE : **"""

from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
#mae
mae = mean_absolute_error(y_test,y_pred)
print("mae for LR model : ", mae)
mse = mean_squared_error(y_test,y_pred)
print("mse for LR model : ", mse)
r2_score = r2_score(y_test,y_pred)
print("r2_score for LR model : ", r2_score)

"""# **2)Trying Decision tree regression algo : **"""

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=250)

from sklearn.tree import DecisionTreeRegressor
#intializing model
DT_model = DecisionTreeRegressor()
DT_model.fit(X_train,y_train)

y_pred_DT = DT_model.predict(X_test)

"""EVALUATING PERFORMANCE:"""

from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
mae_DT = mean_absolute_error(y_test,y_pred_DT)
print("mae for LR model : ", mae_DT)
mse_DT = mean_squared_error(y_test,y_pred_DT)
print("mse for LR model : ", mse_DT)
r2_score_DT = r2_score(y_test,y_pred_DT)
print("r2_score for LR model : ", r2_score_DT)

"""# Conclusion : Decision tree model is a good model  with r2 _score reaching 0.978

# Feature importance : Analysis
"""

feature_importances = pd.DataFrame(DT_model.feature_importances_,
                                   index = X_train.columns,
                                   columns=['Importance']).sort_values('Importance', ascending=False)

feature_importances.describe()

feature_importances.info()

print("Top 4 most important features affecting restaurant ratings:")
print(feature_importances.head(4))

# Ploting the  feature importances
plt.figure(figsize=(15, 3))
sns.barplot(x=feature_importances['Importance'], y=feature_importances.index)
plt.xlabel('Importance')
plt.ylabel('Features')
plt.title('Feature Importances')
plt.show()