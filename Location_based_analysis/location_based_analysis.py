# -*- coding: utf-8 -*-
"""Location_based_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yaJq7-VK3N-rNUjK3w4lZEPxvGa-emWV

# Objective: Perform a geographical analysis of the restaurants in the dataset.

Loading data and python environment needed
"""

import pandas as pd
import folium  # For map visualization : interactive maps
import matplotlib.pyplot as plt  # For chart vizualization

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/data_cognifyz/Dataset .csv')

df.head()

df.columns

"""# Exploring the attributes : longitute and latitude"""

print(df[['Latitude', 'Longitude']].describe())  # Descriptive statistics

plt.figure(figsize=(10, 6))
plt.scatter(df['Longitude'], df['Latitude'], alpha=0.5)
plt.title('Longitude vs Latitude of Restaurants')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.grid(True)
plt.show()

"""# 1.2 ) Visualizing Restaurant Distribution on a Map"""

m = folium.Map(location=[df['Latitude'].mean(), df['Longitude'].mean()], zoom_start=10)
for i, row in df.iterrows():
    folium.Marker([row['Latitude'], row['Longitude']], tooltip=f"{row['Restaurant Name']}")\
        .add_to(m)
folium.LayerControl().add_to(m)
m

"""# Analysis of concentration of resturants in diff areas."""

#grouping resturants by city :
restaurant_counts = df['City'].value_counts().sort_values(ascending=False)
#taking out first 15 cities that have most resturants for ease of vizualization and analysis
restaurant_counts_1 = pd.DataFrame(df['City'].value_counts().sort_values(ascending=False)[:15])
print(f"Top 5 Cities/Localities with most restaurants:\n{restaurant_counts.head()}")

#plotting the analysis for top 15 cities:
import seaborn as sns
restaurant_counts_1.plot(kind='bar',figsize=(10,6))
plt.title(' Restaurants grouped by city present in')
plt.xlabel('Top 20 cities with most restaurants ')
plt.ylabel('No of resturants')
plt.show()

df.columns

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
df['Cuisines'] = imputer.fit_transform(df[['Cuisines']])
df['Cuisines']=df['Cuisines'].apply(lambda x: x.split(','))

"""Location grouping"""

df_1 = df.copy()

location_count = dict(df_1['Address'].value_counts().sort_values(ascending=False)[:15])
print(location_count)

locality_count = dict(df_1['Locality'].value_counts().sort_values(ascending=False)[:25])
print(locality_count)

#plotting the analysis for top 15 localities:
import seaborn as sns
import numpy as np

localities = list(locality_count.keys())
counts = list(locality_count.values())
y_pos = np.arange(len(localities))

plt.figure(figsize=(15, 5))
plt.bar(y_pos, counts, align='center', alpha=0.5)
plt.xticks(y_pos, localities, rotation=90)
plt.xlabel("locality")
plt.ylabel("Number of Restaurants")
plt.title("Top 25 localities with Most Restaurants")
plt.show()

"""# Calculating Statistics by City or Locality"""

print(restaurant_counts_1)

restaurants_by_location = df_1.groupby('City')
restaurant_count_by_location = restaurants_by_location.size().reset_index(name='restaurant_count')
restaurant_count_by_location = pd.DataFrame(restaurant_count_by_location.sort_values(by='restaurant_count', ascending=False)[:15])
restaurant_count_by_location.shape

df_1.columns

#Calculate average ratings by city
average_ratings_by_location = restaurants_by_location['Aggregate rating'].mean().reset_index(name='average_rating')
#Calculate popular cuisines by city
popular_cuisines_by_location = restaurants_by_location['Cuisines'].apply(lambda x: x.mode()).reset_index(name='popular_cuisine')
#Merging average ratings and popular cuisines into one DataFrame
stats_by_location = pd.DataFrame(pd.merge(average_ratings_by_location, popular_cuisines_by_location, on='City'))
#Displaying the statistics
print(stats_by_location)

stats_by_location = pd.DataFrame(pd.merge(average_ratings_by_location, popular_cuisines_by_location, on='City'))
stats_by_location.shape

stats_by_location.columns

plt.figure(figsize=(10, 5))
sns.barplot(x='City', y='average_rating', data=stats_by_location, palette='muted', hue='City', legend=False)
plt.title('Average Ratings by City')
plt.xlabel('City')
plt.ylabel('Average Rating')
plt.xticks(rotation=45)
plt.show()

#Plotting popular cuisines
stats_by_location = stats_by_location.explode('popular_cuisine')

# Plotting popular cuisines
plt.figure(figsize=(10, 5))
sns.countplot(x='popular_cuisine', data=stats_by_location, palette='muted',hue='City', legend=False, order=stats_by_location['popular_cuisine'].value_counts().index)
plt.title('Popular Cuisine by City')
plt.xlabel('Popular Cuisine')
plt.ylabel('Count')
plt.xticks(rotation=55)
plt.show()

"""# Concluding Inshights :
This task marks my 3rd and last task as an ML intern at cognifyz.
Following are the inshights from the above analysis of Restaurant dataset:
1)Top 3 cities with most restaurant are:
New Delhi - 5473 , Gurgaon - 1118 ,Noida - 1080
2)Top 3 localities with most restaurant are:
Connaught Place': 122, 'Rajouri Garden': 99, 'Shahdara': 87
3)The most popular cuisine was North Indian
"""